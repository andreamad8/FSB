{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_model\n",
    "from prompts.generic_prompt import load_prefix, load_prefix_by_category, generate_response_interactive\n",
    "from prompts.image_chat import convert_sample_to_shot_IC_prefix_interact, convert_sample_to_shot_IC_interact\n",
    "import pprint\n",
    "import random\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "args = type('', (), {})()\n",
    "args.multigpu = False\n",
    "device = 0\n",
    "\n",
    "## To use GPT-Jumbo (178B) set this to true and input your api-key\n",
    "## Visit https://studio.ai21.com/account for more info\n",
    "## AI21 provides 10K tokens per day, so you can try only for few turns\n",
    "api = False\n",
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the config dictionary used to select the template converter\n",
    "mapper = {\n",
    "          \"IC\": {\"shot_converter\":convert_sample_to_shot_IC_prefix_interact, \n",
    "                 \"shot_converter_inference\": convert_sample_to_shot_IC_interact,\n",
    "                 \"file_data\":\"data/image_chat/\",\"with_knowledge\":False,\n",
    "                  \"shots\":{1024:[0,1,5],2048:[0,1,10]},\"max_shot\":{1024:5,2048:10},\n",
    "                  \"shot_separator\":\"\\n\\n\",\n",
    "                  \"meta_type\":\"all_turns_category\",\"gen_len\":50,\"max_number_turns\":5},\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if api:\n",
    "    from transformers import AutoTokenizer \n",
    "    tokenizer = tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    model = None\n",
    "    max_seq = 2048\n",
    "else:\n",
    "    ## Load LM and tokenizer\n",
    "    ## You can try different LMs: \n",
    "    ##   gpt2, gpt2-medium, gpt2-large, gpt2-xl,\n",
    "    ##   EleutherAI/gpt-neo-1.3B, EleutherAI/gpt-neo-2.7B,\n",
    "    ##   EleutherAI/gpt-j-6B\n",
    "    ## the larger the better\n",
    "    model, tokenizer, max_seq = load_model(args,\"EleutherAI/gpt-neo-1.3B\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## sample time is used to sample different prompts\n",
    "## we select the zero element of the list\n",
    "## to change the behaviour you could try different prompts\n",
    "prefix_dict = load_prefix_by_category(tokenizer=tokenizer, \n",
    "                                      shots_value=mapper[\"IC\"][\"shots\"][max_seq], \n",
    "                                      shot_converter=mapper[\"IC\"][\"shot_converter\"], \n",
    "                                      file_shot=mapper[\"IC\"][\"file_data\"]+\"valid.json\", \n",
    "                                      name_dataset=\"IC\", with_knowledge=mapper[\"IC\"][\"with_knowledge\"], \n",
    "                                      shot_separator=mapper[\"IC\"][\"shot_separator\"],sample_times=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "prompt_sytle = {}\n",
    "for sty in prefix_dict.keys():\n",
    "    sty_name = sty.replace(\" \",\"-\").replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").split(\"_\")[0]\n",
    "    prompt_sytle[sty_name] = prefix_dict[sty]\n",
    "\n",
    "styles = \", \".join(list(prompt_sytle.keys()))\n",
    "print(f\"The possible styles are \\n {styles}\")\n",
    "dialogue = {\"dialogue\":[],\"personalities\":\"\"}\n",
    "while True: \n",
    "    user_utt = input(\">>> \")\n",
    "    dialogue[\"dialogue\"].append([user_utt,\"\"])\n",
    "    print(\"Choose a style from the list!\")\n",
    "    style = input(\">>> \")\n",
    "    if style not in prompt_sytle.keys():\n",
    "        print(\"You have to choose a style from the list!\")\n",
    "        print(\"This time a random style is selected!\")\n",
    "        style = random.sample(list(prompt_sytle.keys()), 1)[0]\n",
    "        print(f\"You got the {style} style!\")\n",
    "    dialogue[\"personalities\"] = style\n",
    "    prefix_shots = prompt_sytle[style]\n",
    "\n",
    "    prefix = prefix_shots.get(mapper[\"IC\"][\"max_shot\"][max_seq])\n",
    "    response = generate_response_interactive(model, tokenizer, shot_converter=mapper[\"IC\"][\"shot_converter_inference\"], \n",
    "                                                dialogue=dialogue, prefix=prefix, \n",
    "                                                device=device, max_number_turns=mapper[\"IC\"][\"max_number_turns\"], \n",
    "                                                with_knowledge=mapper[\"IC\"][\"with_knowledge\"], \n",
    "                                                meta_type=mapper[\"IC\"][\"meta_type\"], gen_len=50, \n",
    "                                                beam=1, max_seq=max_seq, eos_token_id=198, \n",
    "                                                do_sample=True, multigpu=False, api=api, api_key=api_key)\n",
    "                    \n",
    "\n",
    "    print(f\"FSB ({style}) >>> {response}\")\n",
    "    dialogue[\"dialogue\"][-1][1] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python371064bit2821c06c19f04f5b9ccde7ca4af69bcf",
   "display_name": "Python 3.7.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}